#!/usr/bin/env python
# vim:fileencoding=utf-8

from calibre.web.feeds.news import BasicNewsRecipe
import json
import os
import tempfile

try:
    from urllib.request import Request, urlopen
    from urllib.error import HTTPError, URLError
except ImportError:
    from urllib2 import Request, urlopen, HTTPError, URLError


class ReadwiseReader(BasicNewsRecipe):
    title = 'Readwise Reader'
    __author__ = 'Ryan'
    description = 'Fetch articles from your Readwise Reader inbox'
    language = 'en'
    encoding = 'utf-8'
    no_stylesheets = True
    remove_javascript = True
    ignore_duplicate_articles = {'url'}
    needs_subscription = True
    auto_cleanup = False

    # Default settings
    max_articles_per_feed = 20
    oldest_article = 365

    # Recipe-specific options for user configuration
    recipe_specific_options = {
        'max_articles': {
            'short': 'Maximum articles',
            'long': 'Maximum number of articles to download (default: 20)',
            'default': '20'
        }
    }

    # Readwise API configuration
    API_BASE = 'https://readwise.io/api/v3'

    def get_cover_url(self):
        return None

    def _get_token(self):
        """Get the API token from Calibre's password field."""
        if not self.password:
            raise ValueError(
                'Readwise API token is required. '
                'Enter your token in the password field. '
                'Get your token at: https://readwise.io/access_token'
            )
        return self.password.strip()

    def _api_request(self, endpoint, params=None):
        """Make an authenticated request to the Readwise API."""
        token = self._get_token()
        url = f'{self.API_BASE}/{endpoint}'

        if params:
            query_string = '&'.join(f'{k}={v}' for k, v in params.items())
            url = f'{url}?{query_string}'

        request = Request(url)
        request.add_header('Authorization', f'Token {token}')
        request.add_header('Accept', 'application/json')

        try:
            response = urlopen(request, timeout=30)
            return json.loads(response.read().decode('utf-8'))
        except HTTPError as e:
            if e.code == 401:
                raise ValueError(
                    'Invalid API token. Please check your Readwise API token. '
                    'Get a valid token at: https://readwise.io/access_token'
                )
            elif e.code == 429:
                raise ValueError(
                    'Rate limited by Readwise API. Please try again later.'
                )
            else:
                raise ValueError(f'API request failed: HTTP {e.code}')
        except URLError as e:
            raise ValueError(f'Network error: {e.reason}')

    def _fetch_articles(self, max_count):
        """Fetch articles from Readwise Reader inbox."""
        articles = []
        cursor = None

        while len(articles) < max_count:
            params = {
                'location': 'new',
                'category': 'article',
                'withHtmlContent': 'true',
                'pageSize': min(100, max_count - len(articles))
            }

            if cursor:
                params['pageCursor'] = cursor

            data = self._api_request('list/', params)
            results = data.get('results', [])

            if not results:
                break

            articles.extend(results)
            cursor = data.get('nextPageCursor')

            if not cursor:
                break

        return articles[:max_count]

    def _build_html(self, content, title, author):
        """Build a complete HTML document from article content."""
        from html import escape
        safe_title = escape(title) if title else 'Untitled'
        author_line = f'<p class="author">By {escape(author)}</p>' if author else ''

        return f'''<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <title>{safe_title}</title>
</head>
<body>
    <article>
        <h1>{safe_title}</h1>
        {author_line}
        <div class="content">
            {content}
        </div>
    </article>
</body>
</html>'''

    def parse_index(self):
        """Parse the Readwise Reader API and return article index."""
        # Get max articles from recipe options
        max_articles = 20
        if hasattr(self, 'recipe_specific_options'):
            try:
                opt_value = self.get_recipe_specific_option('max_articles')
                if opt_value:
                    max_articles = int(opt_value)
            except (ValueError, AttributeError):
                pass

        self.log(f'Fetching up to {max_articles} articles from Readwise Reader inbox...')

        try:
            articles = self._fetch_articles(max_articles)
        except ValueError as e:
            self.log.error(str(e))
            raise

        if not articles:
            self.log.warn('No articles found in your Readwise Reader inbox.')
            return []

        self.log(f'Found {len(articles)} articles')

        # Sort by saved date (most recent first)
        articles.sort(key=lambda x: x.get('saved_at', x.get('created_at', '')), reverse=True)

        # Create temp directory for article HTML files
        self._temp_dir = tempfile.mkdtemp(prefix='readwise_reader_')
        self.log(f'Using temp directory: {self._temp_dir}')

        # Build the article index
        feed_articles = []
        for idx, article in enumerate(articles):
            title = article.get('title') or 'Untitled'
            url = article.get('source_url') or article.get('url', '')
            author = article.get('author', '')
            summary = article.get('summary', '')
            html_content = article.get('html_content', '')

            if not html_content:
                self.log.warn(f'Skipping "{title}" - no HTML content available')
                continue

            # Write HTML to temp file
            html = self._build_html(html_content, title, author)
            filename = f'article_{idx}.html'
            filepath = os.path.join(self._temp_dir, filename)

            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(html)

            self.log(f'Saved article: {title}')

            feed_articles.append({
                'title': title,
                'url': 'file://' + filepath,
                'author': author,
                'description': summary,
            })

        if not feed_articles:
            self.log.warn('No articles with content found.')
            return []

        self.log(f'Prepared {len(feed_articles)} articles for download')
        return [('Readwise Reader Inbox', feed_articles)]

    def preprocess_html(self, soup):
        """Clean up the HTML before conversion."""
        # Remove any script tags that might have slipped through
        for script in soup.find_all('script'):
            script.decompose()

        # Remove style tags
        for style in soup.find_all('style'):
            style.decompose()

        return soup
